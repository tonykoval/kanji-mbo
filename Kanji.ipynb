{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a757cb24",
   "metadata": {},
   "source": [
    "### Categorize kanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9130116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-4s %(message)s', datefmt='%m/%d %H:%M:%S')\n",
    "\n",
    "# data classes\n",
    "@dataclass        \n",
    "class Kanji:\n",
    "    rank: int\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413aaccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAR</th>\n",
       "      <th>COMPONENTS1</th>\n",
       "      <th>COMPONENTS2</th>\n",
       "      <th>COMPONENTS3</th>\n",
       "      <th>COMPONENTS4</th>\n",
       "      <th>COMPONENTS5</th>\n",
       "      <th>ON READING</th>\n",
       "      <th>KUN READING</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>SRL</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>TAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>イチ、イツ</td>\n",
       "      <td>ひと・つ</td>\n",
       "      <td>one</td>\n",
       "      <td>5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>二</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ニ</td>\n",
       "      <td>ふた・つ</td>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>MEAN</td>\n",
       "      <td>128.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>三</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>サン</td>\n",
       "      <td>みっ・つ</td>\n",
       "      <td>three</td>\n",
       "      <td>5</td>\n",
       "      <td>MEAN</td>\n",
       "      <td>120.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>四</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>シ</td>\n",
       "      <td>よっ・つ、よん、よ</td>\n",
       "      <td>four</td>\n",
       "      <td>5</td>\n",
       "      <td>MEAN</td>\n",
       "      <td>312.073333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>五</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ゴ</td>\n",
       "      <td>いつ・つ</td>\n",
       "      <td>five</td>\n",
       "      <td>5</td>\n",
       "      <td>MEAN</td>\n",
       "      <td>315.626667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>気</td>\n",
       "      <td>气</td>\n",
       "      <td>㐅</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>キ、ケ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>風</td>\n",
       "      <td>𠘨</td>\n",
       "      <td>䖝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>フウ、フ</td>\n",
       "      <td>かぜ</td>\n",
       "      <td>1 wind 2 style</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>289.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>乳</td>\n",
       "      <td>⺤</td>\n",
       "      <td>子</td>\n",
       "      <td>乚</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ニュウ</td>\n",
       "      <td>ち、ちち</td>\n",
       "      <td>milk</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>興</td>\n",
       "      <td>臼</td>\n",
       "      <td>同</td>\n",
       "      <td>ハ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>コウ、キョウ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interest</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>649.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>疑</td>\n",
       "      <td>𠤕</td>\n",
       "      <td>マ</td>\n",
       "      <td>疋</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ギ</td>\n",
       "      <td>うたが・う</td>\n",
       "      <td>doubt</td>\n",
       "      <td>1</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>710.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHAR COMPONENTS1 COMPONENTS2 COMPONENTS3 COMPONENTS4 COMPONENTS5  \\\n",
       "0       一         NaN         NaN         NaN         NaN         NaN   \n",
       "1       二         NaN         NaN         NaN         NaN         NaN   \n",
       "2       三         NaN         NaN         NaN         NaN         NaN   \n",
       "3       四         NaN         NaN         NaN         NaN         NaN   \n",
       "4       五         NaN         NaN         NaN         NaN         NaN   \n",
       "...   ...         ...         ...         ...         ...         ...   \n",
       "1495    気           气           㐅         NaN         NaN         NaN   \n",
       "1496    風           𠘨           䖝         NaN         NaN         NaN   \n",
       "1497    乳           ⺤           子           乚         NaN         NaN   \n",
       "1498    興           臼           同           ハ         NaN         NaN   \n",
       "1499    疑           𠤕           マ           疋         NaN         NaN   \n",
       "\n",
       "     ON READING KUN READING         KEYWORD  SRL   TYPE         FREQ  TAGS  \n",
       "0         イチ、イツ        ひと・つ             one    5   STEM    10.800000   NaN  \n",
       "1             ニ        ふた・つ             two    5   MEAN   128.300000   NaN  \n",
       "2            サン        みっ・つ           three    5   MEAN   120.700000   NaN  \n",
       "3             シ   よっ・つ、よん、よ            four    5   MEAN   312.073333   NaN  \n",
       "4             ゴ        いつ・つ            five    5   MEAN   315.626667   NaN  \n",
       "...         ...         ...             ...  ...    ...          ...   ...  \n",
       "1495        キ、ケ         NaN      atmosphere    1  OTHER    64.000000   NaN  \n",
       "1496       フウ、フ          かぜ  1 wind 2 style    1  OTHER   289.700000   NaN  \n",
       "1497        ニュウ        ち、ちち            milk    1  OTHER  1067.000000   NaN  \n",
       "1498     コウ、キョウ         NaN        interest    1  OTHER   649.600000   NaN  \n",
       "1499          ギ       うたが・う           doubt    1  OTHER   710.600000   NaN  \n",
       "\n",
       "[1500 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file (with mapping)\n",
    "df_kanji = pandas.read_excel(\"1500 KANJI COMPONENTS - ver. 1.2.xlsx\", sheet_name=\"MAIN\")\n",
    "df_kanji.columns = [\"CHAR\", \"COMPONENTS1\", \"COMPONENTS2\", \"COMPONENTS3\", \"COMPONENTS4\", \"COMPONENTS5\", \"ON READING\", \"KUN READING\", \"KEYWORD\", \"SRL\", \"TYPE\", \"FREQ\", \"TAGS\"]\n",
    "df_kanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3e27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keyword = pandas.read_excel(\"1500 KANJI COMPONENTS - ver. 1.2.xlsx\", sheet_name=\"keyword.list\")\n",
    "# df_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6df762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stem = pandas.read_excel(\"1500 KANJI COMPONENTS - ver. 1.2.xlsx\", sheet_name=\"stem.list\")\n",
    "# df_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdaac0",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "347cbe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHAR                       弁\n",
       "COMPONENTS1                厶\n",
       "COMPONENTS2                廾\n",
       "COMPONENTS3              NaN\n",
       "COMPONENTS4              NaN\n",
       "COMPONENTS5              NaN\n",
       "ON READING                ベン\n",
       "KUN READING              NaN\n",
       "KEYWORD        clarification\n",
       "SRL                        1\n",
       "TYPE                  VISUAL\n",
       "FREQ                  1609.5\n",
       "TAGS                     NaN\n",
       "Name: 61, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_row = df_kanji[df_kanji[\"CHAR\"] == '弁'].iloc[0]\n",
    "random_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22596826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 numbers': [],\n",
       " '2 family': [],\n",
       " '3 colors': [],\n",
       " '31 cardinals': [],\n",
       " '32 season of the year': [],\n",
       " '33 parts of the day': [],\n",
       " '77 other': [],\n",
       " '4 Sunday': [],\n",
       " '5 Monday': [],\n",
       " '6 Tuesday': [],\n",
       " '7 flame': [],\n",
       " '8 Wednesday': [],\n",
       " '9 alcohol': [],\n",
       " '10 Thursday': [],\n",
       " '11 Friday': [],\n",
       " '12 Saturday': [],\n",
       " '13 human': [],\n",
       " '14 woman': [],\n",
       " '15 child': [],\n",
       " '16 ear': [],\n",
       " '17 eye': [],\n",
       " '18 to see': [],\n",
       " '19 mouth': [],\n",
       " '20 tongue': [],\n",
       " '21 talk': [],\n",
       " '22 beard': [],\n",
       " '23 heart': [],\n",
       " '24 arm': [],\n",
       " '25 leg': [],\n",
       " '26 kneel': [],\n",
       " '27 stand': [],\n",
       " '28 run': [],\n",
       " '29 route': [],\n",
       " '30 direction': [],\n",
       " '32 seasons of the year': [],\n",
       " '34 car': [],\n",
       " '35 ship': [],\n",
       " '36 rain': [],\n",
       " '37 gate': [],\n",
       " '38 roof A': [],\n",
       " '39 roof B': [],\n",
       " '40 roof C': [],\n",
       " '41 roof D': [],\n",
       " '42 temple': [],\n",
       " '43 insect': [],\n",
       " '44 dog': [],\n",
       " '45 hound': [],\n",
       " '46 sheep': [],\n",
       " '47 cow': [],\n",
       " '48 horse': [],\n",
       " '49 bird': [],\n",
       " '50 feather': [],\n",
       " '51 field': [],\n",
       " '52 mound': [],\n",
       " '53 grass': [],\n",
       " '54 thread': [],\n",
       " '55 bamboo': [],\n",
       " '56 rice': [],\n",
       " '57 grain': [],\n",
       " '58 stone': [],\n",
       " '59 mountain': [],\n",
       " '60 dishes': [],\n",
       " '61 cloth': [],\n",
       " '62 to eat': [],\n",
       " '63 tiny': [],\n",
       " '64 big': [],\n",
       " '65 sword': [],\n",
       " '66 to strike': [],\n",
       " '67 bow': [],\n",
       " '68 arrow': [],\n",
       " '69 pike': [],\n",
       " '70 again': [],\n",
       " '71 halberd': [],\n",
       " '72 axe': [],\n",
       " '73 horn': [],\n",
       " '74 dress': [],\n",
       " '75 ka': [],\n",
       " '76 ta': [],\n",
       " '78 special': [],\n",
       " 'visual': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorization = {}\n",
    "special_grp = '78 special'\n",
    "other_grp = '77 other'\n",
    "\n",
    "for grp in df_keyword[\"GROUP\"].unique():\n",
    "    categorization[grp] = []\n",
    "\n",
    "for grp in df_stem[\"GROUP\"].unique():\n",
    "    categorization[grp] = []\n",
    "\n",
    "categorization[other_grp] = []\n",
    "categorization[special_grp] = []\n",
    "categorization[\"visual\"] = []\n",
    "\n",
    "# categorization[\"1 numbers\"] = []\n",
    "# categorization[\"1 numbers\"].append(Test(\"aa\", \"bb\"))\n",
    "# categorization[\"1 numbers\"].append(Test(\"ca\", \"ab\"))\n",
    "# categorization[\"1 numbers\"].insert(0, Test(\"xxx\", \"ab\"))\n",
    "\n",
    "# categorization\n",
    "\n",
    "queue_categorization = {}\n",
    "categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93ef9350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components count: 0\n",
      "4. rule\n",
      "vr clusters\n",
      "5. rule\n",
      "6. rule\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1 numbers': [],\n",
       " '2 family': [],\n",
       " '3 colors': [],\n",
       " '31 cardinals': [],\n",
       " '32 season of the year': [],\n",
       " '33 parts of the day': [],\n",
       " '77 other': [],\n",
       " '4 Sunday': [],\n",
       " '5 Monday': [],\n",
       " '6 Tuesday': [],\n",
       " '7 flame': [],\n",
       " '8 Wednesday': [],\n",
       " '9 alcohol': [],\n",
       " '10 Thursday': [],\n",
       " '11 Friday': [],\n",
       " '12 Saturday': [],\n",
       " '13 human': [],\n",
       " '14 woman': [],\n",
       " '15 child': [],\n",
       " '16 ear': [],\n",
       " '17 eye': [],\n",
       " '18 to see': [],\n",
       " '19 mouth': [],\n",
       " '20 tongue': [],\n",
       " '21 talk': [],\n",
       " '22 beard': [],\n",
       " '23 heart': [],\n",
       " '24 arm': [],\n",
       " '25 leg': [],\n",
       " '26 kneel': [],\n",
       " '27 stand': [],\n",
       " '28 run': [],\n",
       " '29 route': [],\n",
       " '30 direction': [],\n",
       " '32 seasons of the year': [],\n",
       " '34 car': [],\n",
       " '35 ship': [],\n",
       " '36 rain': [],\n",
       " '37 gate': [],\n",
       " '38 roof A': [],\n",
       " '39 roof B': [],\n",
       " '40 roof C': [],\n",
       " '41 roof D': [],\n",
       " '42 temple': [],\n",
       " '43 insect': [],\n",
       " '44 dog': [],\n",
       " '45 hound': [],\n",
       " '46 sheep': [],\n",
       " '47 cow': [],\n",
       " '48 horse': [],\n",
       " '49 bird': [],\n",
       " '50 feather': [],\n",
       " '51 field': [],\n",
       " '52 mound': [],\n",
       " '53 grass': [],\n",
       " '54 thread': [],\n",
       " '55 bamboo': [],\n",
       " '56 rice': [],\n",
       " '57 grain': [],\n",
       " '58 stone': [],\n",
       " '59 mountain': [],\n",
       " '60 dishes': [],\n",
       " '61 cloth': [],\n",
       " '62 to eat': [],\n",
       " '63 tiny': [],\n",
       " '64 big': [],\n",
       " '65 sword': [],\n",
       " '66 to strike': [],\n",
       " '67 bow': [],\n",
       " '68 arrow': [],\n",
       " '69 pike': [],\n",
       " '70 again': [],\n",
       " '71 halberd': [],\n",
       " '72 axe': [],\n",
       " '73 horn': [],\n",
       " '74 dress': [],\n",
       " '75 ka': [],\n",
       " '76 ta': [],\n",
       " '78 special': [],\n",
       " 'visual': [CHAR                       弁\n",
       "  COMPONENTS1                厶\n",
       "  COMPONENTS2                廾\n",
       "  COMPONENTS3              NaN\n",
       "  COMPONENTS4              NaN\n",
       "  COMPONENTS5              NaN\n",
       "  ON READING                ベン\n",
       "  KUN READING              NaN\n",
       "  KEYWORD        clarification\n",
       "  SRL                        1\n",
       "  TYPE                  VISUAL\n",
       "  FREQ                  1609.5\n",
       "  TAGS                     NaN\n",
       "  Name: 61, dtype: object,\n",
       "  CHAR                       弁\n",
       "  COMPONENTS1                厶\n",
       "  COMPONENTS2                廾\n",
       "  COMPONENTS3              NaN\n",
       "  COMPONENTS4              NaN\n",
       "  COMPONENTS5              NaN\n",
       "  ON READING                ベン\n",
       "  KUN READING              NaN\n",
       "  KEYWORD        clarification\n",
       "  SRL                        1\n",
       "  TYPE                  VISUAL\n",
       "  FREQ                  1609.5\n",
       "  TAGS                     NaN\n",
       "  Name: 61, dtype: object]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"char: \", random_row)\n",
    "\n",
    "# first rule (check keyword)\n",
    "def find_keyword(row):\n",
    "    group = df_keyword[df_keyword[\"KEYWORD\"] == row[\"KEYWORD\"]][\"GROUP\"]\n",
    "    if group.empty:\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return group.iloc[0]\n",
    "\n",
    "def find_stem(row):\n",
    "    group = df_stem[df_stem[\"STEM KANJI\"] == row[\"CHAR\"]][\"GROUP\"]\n",
    "    if group.empty:\n",
    "        return \"none\"\n",
    "    else:\n",
    "        return group.iloc[0]\n",
    "    \n",
    "def append_categorization(char, row, is_first):\n",
    "    if is_first:\n",
    "        if char in queue_categorization.keys():\n",
    "            for ch in queue_categorization[char]:\n",
    "                categorization[char].insert(0, ch)\n",
    "            categorization[char].insert(0, row)\n",
    "        else:\n",
    "            categorization[char].insert(0, row)\n",
    "    else:\n",
    "        if char in queue_categorization.keys():\n",
    "            categorization[char].append(row)\n",
    "            for ch in queue_categorization[char]:\n",
    "                categorization[char].append(ch)\n",
    "        else:\n",
    "            categorization[char].append(row)\n",
    "\n",
    "def find_cluster_1_2_components(component, row):\n",
    "    return df_kanji[\n",
    "        ((df_kanji[\"COMPONENTS1\"] == row[component]) | \n",
    "         (df_kanji[\"COMPONENTS2\"] == row[component])) \n",
    "        & (df_kanji[\"CHAR\"] != row[\"CHAR\"])\n",
    "    ]\n",
    "\n",
    "def find_cluster_components(component, row):\n",
    "    return df_kanji[\n",
    "        ((df_kanji[\"COMPONENTS2\"] == row[component]) | \n",
    "         (df_kanji[\"COMPONENTS3\"] == row[component]) |\n",
    "         (df_kanji[\"COMPONENTS4\"] == row[component]) |\n",
    "         (df_kanji[\"COMPONENTS5\"] == row[component])) \n",
    "        & (df_kanji[\"CHAR\"] != row[\"CHAR\"])\n",
    "    ]\n",
    "\n",
    "def find_cluster_all_components(component, row):\n",
    "    return df_kanji[\n",
    "        ((df_kanji[\"COMPONENTS1\"] == row[component]) | \n",
    "        (df_kanji[\"COMPONENTS2\"] == row[component]) | \n",
    "        (df_kanji[\"COMPONENTS3\"] == row[component]) |\n",
    "        (df_kanji[\"COMPONENTS4\"] == row[component]) |\n",
    "        (df_kanji[\"COMPONENTS5\"] == row[component]))\n",
    "        & (df_kanji[\"CHAR\"] != row[\"CHAR\"])\n",
    "    ]\n",
    "\n",
    "def find_onyomi(random_row, vr_cluster):\n",
    "    vr_crowns = random_row[\"ON READING\"].split(\"、\")\n",
    "    onyomi = vr_cluster[vr_cluster[\"ON READING\"].isin(vr_crowns)]\n",
    "    if onyomi.empty:\n",
    "        fifth_rule(random_row)\n",
    "    else:\n",
    "        if len(onyomi.index) > 1:\n",
    "            print(\"kanji > 1\")\n",
    "            max_srl_kanji = onyomi[onyomi[\"SRL\"] == onyomi[\"SRL\"].max()].iloc[0]\n",
    "            random_row[\"TYPE\"] = \"VR\"\n",
    "\n",
    "            if max_srl_kanji[\"CHAR\"] in queue_categorization.keys():\n",
    "                queue_categorization[max_srl_kanji[\"CHAR\"]].append(random_row)\n",
    "            else:\n",
    "                queue_categorization[max_srl_kanji[\"CHAR\"]] = []\n",
    "                queue_categorization[max_srl_kanji[\"CHAR\"]].append(random_row)\n",
    "        else:\n",
    "            print(\"kanji = 1\")\n",
    "            random_row[\"TYPE\"] = \"VR\"\n",
    "            max_srl_kanji = onyomi.iloc[0]\n",
    "            if max_srl_kanji[\"CHAR\"] in queue_categorization.keys():\n",
    "                queue_categorization[onyomi.iloc[0][\"CHAR\"]].append(random_row)\n",
    "            else:\n",
    "                queue_categorization[onyomi.iloc[0][\"CHAR\"]] = []\n",
    "                queue_categorization[onyomi.iloc[0][\"CHAR\"]].append(random_row)\n",
    "\n",
    "def seventh_rule(random_row):\n",
    "    print(\"7. rule\")\n",
    "                \n",
    "def sixth_rule(random_row):\n",
    "    print(\"6. rule\")\n",
    "    vr_cluster_1_2 = pandas.concat([\n",
    "        find_cluster_1_2_components(\"COMPONENTS1\", random_row), \n",
    "        find_cluster_1_2_components(\"COMPONENTS2\", random_row)\n",
    "    ])\n",
    "    if vr_cluster_1_2.empty:\n",
    "        seventh_rule(random_row)\n",
    "    else:\n",
    "        if len(vr_cluster_1_2.index) > 1:\n",
    "            append_categorization(\"visual\", random_row, False)\n",
    "        else:\n",
    "            random_row[\"TYPE\"] = \"VISUAL\"\n",
    "            max_srl_kanji = vr_cluster_1_2.iloc[0]\n",
    "            if max_srl_kanji[\"CHAR\"] in queue_categorization.keys():\n",
    "                queue_categorization[vr_cluster_1_2.iloc[0][\"CHAR\"]].append(random_row)\n",
    "            else:\n",
    "                queue_categorization[vr_cluster_1_2.iloc[0][\"CHAR\"]] = []\n",
    "                queue_categorization[vr_cluster_1_2.iloc[0][\"CHAR\"]].append(random_row)\n",
    "                \n",
    "def fifth_rule(random_row):\n",
    "    print(\"5. rule\")\n",
    "    group_stem = df_stem[\n",
    "        (df_stem[\"STEM KANJI\"] == random_row[\"COMPONENTS1\"]) |\n",
    "        (df_stem[\"STEM KANJI\"] == random_row[\"COMPONENTS2\"]) |\n",
    "        (df_stem[\"STEM KANJI\"] == random_row[\"COMPONENTS3\"])\n",
    "    ][\"GROUP\"]\n",
    "    if group_stem.empty:\n",
    "        sixth_rule(random_row)\n",
    "    else:\n",
    "        if (random_row[\"SRL\"] == 1):\n",
    "            random_row[\"TYPE\"] = \"FORM\"\n",
    "        else:\n",
    "            random_row[\"TYPE\"] = \"MEAN\"\n",
    "        if len(group_stem) == 1: \n",
    "            append_categorization(group_stem.iloc[0], random_row, False)\n",
    "        else:\n",
    "            print(\"more stems TODO\")\n",
    "                \n",
    "def fourth_rule(random_row):\n",
    "    print(\"4. rule\")\n",
    "    vr_cluster = pandas.concat([\n",
    "        find_cluster_components(\"COMPONENTS2\", random_row), \n",
    "        find_cluster_components(\"COMPONENTS3\", random_row), \n",
    "        find_cluster_components(\"COMPONENTS4\", random_row), \n",
    "        find_cluster_components(\"COMPONENTS5\", random_row)\n",
    "    ])\n",
    "#     print(\"vr_cluster\", vr_cluster)\n",
    "    if vr_cluster.empty:\n",
    "        vr_all_cluster = pandas.concat([\n",
    "            find_cluster_all_components(\"COMPONENTS1\", random_row),\n",
    "            find_cluster_all_components(\"COMPONENTS2\", random_row),\n",
    "            find_cluster_all_components(\"COMPONENTS3\", random_row),\n",
    "            find_cluster_all_components(\"COMPONENTS4\", random_row),\n",
    "            find_cluster_all_components(\"COMPONENTS5\", random_row)\n",
    "        ])\n",
    "#         print(\"vr_all_cluster\", vr_all_cluster)\n",
    "        if vr_all_cluster.empty:\n",
    "#             vr_third_cluster = df_kanji[df_kanji[\"CHAR\"] == random_row[\"COMPONENTS2\"]]  \n",
    "            print(\"4. rule - 3rd condition TODO\")\n",
    "#             fifth_rule(random_row)\n",
    "        else:\n",
    "            find_onyomi(random_row, vr_all_cluster)\n",
    "    else:\n",
    "        print(\"vr clusters\")\n",
    "        find_onyomi(random_row, vr_cluster)\n",
    "            \n",
    "first_rule = find_keyword(random_row)\n",
    "second_rule = find_stem(random_row)\n",
    "if (first_rule != \"none\"):\n",
    "    print(\"1. rule\")\n",
    "    if (random_row[\"TYPE\"] == \"MEAN\"):\n",
    "        append_categorization(first_rule, random_row, False)\n",
    "    else:\n",
    "        if (random_row[\"TYPE\"] == \"SPECIAL\"):\n",
    "            append_categorization(special_grp, random_row, False)\n",
    "        else:\n",
    "            if (random_row[\"TYPE\"] == \"OTHER\"):\n",
    "                append_categorization(other_grp, random_row, False)\n",
    "            else:\n",
    "                print(\"ERROR: missing grp\")\n",
    "else:\n",
    "    if (second_rule != \"none\"):\n",
    "        print(\"2. rule\")\n",
    "        if (random_row[\"TYPE\"] == \"STEM\"):\n",
    "            append_categorization(second_rule, random_row, True)\n",
    "        else:\n",
    "            print(\"ERROR: missing rule\")\n",
    "    else:\n",
    "        components = df_kanji[(df_kanji[\"COMPONENTS1\"] == random_row[\"CHAR\"]) | (df_kanji[\"COMPONENTS2\"] == random_row[\"CHAR\"])]\n",
    "        print(\"components count: \" + str(len(components.index)))\n",
    "        if components.empty:\n",
    "            fourth_rule(random_row)\n",
    "        else:\n",
    "            print(\"3. rule\")\n",
    "            vr_crowns = random_row[\"ON READING\"].split(\"、\")\n",
    "            print(vr_crowns)\n",
    "            onyomi = components[components[\"ON READING\"].isin(vr_crowns)]\n",
    "            if onyomi.empty:\n",
    "                print(\"onyomi empty\")\n",
    "                fourth_rule(random_row)\n",
    "            else:\n",
    "                print(\"3. rule a) b)\")\n",
    "                if len(onyomi.index) > 1:\n",
    "                    print(\"kanji > 1\")\n",
    "                    print(onyomi)\n",
    "                    max_srl_kanji = onyomi[onyomi[\"SRL\"] == onyomi[\"SRL\"].max()].iloc[0]\n",
    "                    random_row[\"TAG\"] = \"CROWN_TAG\"\n",
    "                    random_row[\"TYPE\"] = \"VR\"\n",
    "                    \n",
    "                    if max_srl_kanji[\"CHAR\"] in queue_categorization.keys():\n",
    "                        queue_categorization[max_srl_kanji[\"CHAR\"]].append(random_row)\n",
    "                    else:\n",
    "                        queue_categorization[max_srl_kanji[\"CHAR\"]] = []\n",
    "                        queue_categorization[max_srl_kanji[\"CHAR\"]].append(random_row)\n",
    "                else:\n",
    "                    print(\"kanji = 1\")\n",
    "                    random_row[\"TAG\"] = \"CROWN_TAG\"\n",
    "                    random_row[\"TYPE\"] = \"VR\"\n",
    "                    max_srl_kanji = onyomi.iloc[0]\n",
    "                    if max_srl_kanji[\"CHAR\"] in queue_categorization.keys():\n",
    "                        queue_categorization[onyomi.iloc[0][\"CHAR\"]].append(random_row)\n",
    "                    else:\n",
    "                        queue_categorization[onyomi.iloc[0][\"CHAR\"]] = []\n",
    "                        queue_categorization[onyomi.iloc[0][\"CHAR\"]].append(random_row)\n",
    "                    \n",
    "categorization\n",
    "# queue_categorization\n",
    "# find_keyword(random_row)\n",
    "# find_stem(random_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"COMPONENTS1\"] == \"c\"]\n",
    "# mb = mb.dropna(subset=['ON READING'])\n",
    "# mb[mb[\"ON READING\"].str.ns(\"フク\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
